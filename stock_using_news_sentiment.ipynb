{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "92623fcd-54cf-4b6e-87ba-a169c8cba1a0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Predict the daily buy/sell target variable with respect to the news sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ac7d646-21cb-46cc-bcde-b11a66c9b998",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e6c34635-b177-468f-aa8f-caedb9239705",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Data Processing\n",
    "- Calculate sentiment score from the new york times new data using FinBert transformer model.\n",
    "- Calculate percent change in the stock from previous day and calculate labels as buy or sell based on these changes.\n",
    "- Join the 2 dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "811d5a31-c41c-49b9-8eda-42fbce21f881",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@udf\n",
    "def get_sentiment(text):\n",
    "    finbert = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone',num_labels=3)\n",
    "    tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')\n",
    "\n",
    "    nlp = pipeline(\"sentiment-analysis\", model=finbert, tokenizer=tokenizer)\n",
    "    results = nlp(text.split('.'))\n",
    "#     for r in results\n",
    "    df_res = pd.DataFrame(results)\n",
    "    sents = df_res[df_res['label']!='Neutral'].groupby(by='label', as_index=False).count().sort_values(by='score', ascending=False)\n",
    "    score = 0\n",
    "    for i,v in sents.iterrows():\n",
    "        if 'Positive' in v['label']:\n",
    "            score+=v['score']\n",
    "        elif 'Negative' in v['label']:\n",
    "            score-=v['score']\n",
    "#     pos = list(sents[sents['label']=='Positive'].score)[0]\n",
    "#     neg = list(sents[sents['label']=='Negative'].score)[0]\n",
    "#     neg = list(sents[sents['label']=='Neutral'].score)[0]\n",
    "    return score\n",
    "\n",
    "@udf('int')\n",
    "def convert(close_change):\n",
    "    if close_change>=0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16025a1b-fd08-466c-92ea-36586e084ad9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mongo_username = \"####\"\n",
    "mongo_password =  \"####\"\n",
    "mongo_ip_address = \"g14cluster.tlbgg.mongodb.net\"\n",
    "database_name = \"g14_db\"\n",
    "collection_name = \"nyt_news\"\n",
    "connection_string = f\"mongodb+srv://{mongo_username}:{mongo_password}@{mongo_ip_address}/{database_name}.{collection_name}\"\n",
    "\n",
    "df = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\").option(\"uri\",connection_string).load()\n",
    "\n",
    "df = df.filter(df.ticker=='AAPL')\n",
    "df_sentiment = df.withColumn(\"sentiment_para\", get_sentiment(df.lead_paragraph))\n",
    "df_sentiment = df_sentiment.withColumn(\"sentiment_score2\", df_sentiment[\"sentiment_para\"].cast(IntegerType())).drop(\"sentiment_para\")\n",
    "df_sents_grp = df_sentiment.select('date', 'ticker', first('sentiment_score2').over(Window.partitionBy('ticker').orderBy('date')).alias('avg_score'))\n",
    "\n",
    "collection_name = \"ts_da\"\n",
    "connection_string = f\"mongodb+srv://{mongo_username}:{mongo_password}@{mongo_ip_address}/{database_name}.{collection_name}\"\n",
    "\n",
    "df_tsda = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\").option(\"uri\",connection_string).load()\n",
    "\n",
    "df_tsda = df_tsda.filter(df_tsda.symbol=='AAPL')\n",
    "df_tsda_prev = df_tsda.select('amount', 'close', 'coefficient',\n",
    "               'date', 'high', 'low', 'open',\n",
    "               'symbol', 'timezone', 'volume',\n",
    "               lag('close',1).over(Window.partitionBy('symbol').orderBy('date')).alias('prev_close')\n",
    "               )\n",
    "df_tsda_chg = df_tsda_prev.select('amount', 'close', 'coefficient',\n",
    "               'date', 'high', 'low', 'open',\n",
    "               'symbol', 'timezone', 'volume',\n",
    "               ((df_tsda_prev.close-df_tsda_prev.prev_close)/df_tsda_prev.prev_close).alias('close_change')).cache()\n",
    "df_sentnews_tsda=df_tsda_chg\\\n",
    ".join(df_sents_grp, (df_sents_grp.ticker==df_tsda_chg.symbol) & (df_sents_grp.date==df_tsda_chg.date))\\\n",
    ".select(df_tsda_chg.date, 'symbol', 'close_change', log(df_tsda_chg.volume).alias('logvolume'), 'avg_score')\n",
    "\n",
    "df_sentnews_tsda = df_sentnews_tsda.na.drop()\n",
    "df_sentnews_tsda = df_sentnews_tsda.withColumn('buy_sell', convert('close_change'))\n",
    "df_sentnews_tsda = df_sentnews_tsda.withColumn(\"date\",col(\"date\").cast(DateType())).withColumn('date_n',date_add(col('date'),-1).alias('date_n'))\n",
    "df_sentnews_tsda = df_sentnews_tsda.withColumn('month', date_format(col('date_n'),'M').cast(LongType())).withColumn('year', date_format(col('date_n'),'y').cast(LongType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04d67a19-e23a-46e6-bc26-3df2263bd5d6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------------+------------------+---------+--------+----------+-----+----+\n",
      "|      date|symbol|        close_change|         logvolume|avg_score|buy_sell|    date_n|month|year|\n",
      "+----------+------+--------------------+------------------+---------+--------+----------+-----+----+\n",
      "|2022-01-03|  AAPL|0.025004223686435303|18.466621328112897|       -1|       0|2022-01-02|    1|2022|\n",
      "|2022-01-03|  AAPL|0.025004223686435303|18.466621328112897|       -1|       0|2022-01-02|    1|2022|\n",
      "|2022-01-04|  AAPL|-0.01269161035108...|18.413761239301795|       -1|       1|2022-01-03|    1|2022|\n",
      "|2022-01-05|  AAPL|-0.02659988870339...| 18.36450821808277|       -1|       1|2022-01-04|    1|2022|\n",
      "|2022-01-13|  AAPL|-0.01902808636700594|  18.2523302556847|       -1|       1|2022-01-12|    1|2022|\n",
      "|2022-01-18|  AAPL|-0.01889408909689...| 18.32086301640156|       -1|       1|2022-01-17|    1|2022|\n",
      "|2022-01-20|  AAPL|-0.01034710942669...| 18.33098046419263|       -1|       1|2022-01-19|    1|2022|\n",
      "|2022-01-20|  AAPL|-0.01034710942669...| 18.33098046419263|       -1|       1|2022-01-19|    1|2022|\n",
      "|2022-01-25|  AAPL|-0.01138472961266...| 18.56736102110391|       -1|       1|2022-01-24|    1|2022|\n",
      "|2022-01-26|  AAPL|-5.63274502444352E-4|18.500187689669556|       -1|       1|2022-01-25|    1|2022|\n",
      "|2022-01-27|  AAPL|-0.00294320245475...|18.619159713883327|       -1|       1|2022-01-26|    1|2022|\n",
      "|2022-02-01|  AAPL|-9.72651333099015...| 18.27234210312393|       -1|       1|2022-01-31|    1|2022|\n",
      "|2022-02-02|  AAPL|0.007044270087621368|18.257152552379743|       -1|       0|2022-02-01|    2|2022|\n",
      "|2022-02-03|  AAPL|-0.01671974522293047| 18.30883338973251|       -1|       1|2022-02-02|    2|2022|\n",
      "|2022-02-03|  AAPL|-0.01671974522293047| 18.30883338973251|       -1|       1|2022-02-02|    2|2022|\n",
      "|2022-02-03|  AAPL|-0.01671974522293047| 18.30883338973251|       -1|       1|2022-02-02|    2|2022|\n",
      "|2022-02-04|  AAPL|-0.00167727009832...| 18.22788936939528|       -1|       1|2022-02-03|    2|2022|\n",
      "|2022-02-10|  AAPL|-0.02359882005900...|18.324895340247046|       -1|       1|2022-02-09|    2|2022|\n",
      "|2022-02-11|  AAPL|-0.02021845224261...|18.407298469411725|       -1|       1|2022-02-10|    2|2022|\n",
      "|2022-02-16|  AAPL|-0.00138896926905...|17.929288365543954|       -1|       1|2022-02-15|    2|2022|\n",
      "+----------+------+--------------------+------------------+---------+--------+----------+-----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sentnews_tsda.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b9574116-5d63-4f1a-903e-b661aa76ab21",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e08600d-0178-4097-b47a-6e01ced4cc8a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def oneHotEncodeColumns(df, cols):\n",
    "    newdf = df\n",
    "    for c in cols:\n",
    "        # For each given colum, create OneHotEncoder. \n",
    "        # dropLast : Whether to drop the last category in the encoded vector (default: true)\n",
    "        ohe = OneHotEncoder(inputCol=c, outputCol=c+\"-onehot\", dropLast=False)\n",
    "        ohe_model = ohe.fit(newdf)\n",
    "        #Creates a DataFame by putting the transformed values in the new colum with suffix \"-onehot\" \n",
    "        #and then drops the original columns.\n",
    "        #and drop the \"-onehot\" suffix. \n",
    "        newdf = ohe_model.transform(newdf).drop(c)\n",
    "        newdf = newdf.withColumnRenamed(c+\"-onehot\", c)\n",
    "    return newdf\n",
    "\n",
    "cat_cols = ['year', 'month']\n",
    "# new joined and transformed dataframe\n",
    "df_sents_f = oneHotEncodeColumns(df_sentnews_tsda, cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b9a78578-4723-4316-b704-3469125e963f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Create a dataframe with Features and Labels using VectorAssembler + Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cd2405b-3f29-47ab-a024-1af045f7aca7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "reg_incols = ['logvolume', 'avg_score']\n",
    "va = VectorAssembler(outputCol=\"features\",\n",
    "                     inputCols=reg_incols)\n",
    "df_va = va.transform(df_sents_f).select('features', 'buy_sell').withColumnRenamed('buy_sell', 'label')\n",
    "\n",
    "#splitting the data\n",
    "splits = df_va.randomSplit([0.8, 0.2], seed = 1)\n",
    "train = splits[0].cache()\n",
    "validation = splits[1].cache()\n",
    "#setting evaluator\n",
    "reval = BinaryClassificationEvaluator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e35f969-4353-4013-b825-ec2d63c2af99",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43235a49-8d9f-47b1-b62c-d730864e0da8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|[17.7629804723881...|    0|[-0.4175541402589...|[0.39710217077067...|       1.0|\n",
      "|[17.8253622237061...|    1|[-0.3873097214379...|[0.40436509790427...|       1.0|\n",
      "|[17.8883602518576...|    1|[-0.3567665143613...|[0.41174252637443...|       1.0|\n",
      "|[17.9871774077935...|    0|[-0.3088571917200...|[0.42339370988722...|       1.0|\n",
      "|[17.9912298019269...|    0|[-0.3068924776361...|[0.42387343048526...|       1.0|\n",
      "|[18.0321929521760...|    0|[-0.2870323960227...|[0.42873054038109...|       1.0|\n",
      "|[18.0564484003869...|    1|[-0.2752726759302...|[0.43161312153346...|       1.0|\n",
      "|[18.0564484003869...|    1|[-0.2752726759302...|[0.43161312153346...|       1.0|\n",
      "|[18.0664391227952...|    0|[-0.2704288941117...|[0.43280180518680...|       1.0|\n",
      "|[18.0689406748926...|    1|[-0.2692160716478...|[0.43309955841506...|       1.0|\n",
      "|[18.0701830244738...|    1|[-0.2686137458031...|[0.43324745002002...|       1.0|\n",
      "|[18.0789162560408...|    0|[-0.2643796307359...|[0.43428740435801...|       1.0|\n",
      "|[18.0817112156924...|    0|[-0.2630245560786...|[0.43462035120965...|       1.0|\n",
      "|[18.0865830059765...|    0|[-0.2606625758095...|[0.43520083936811...|       1.0|\n",
      "|[18.0865830059765...|    0|[-0.2606625758095...|[0.43520083936811...|       1.0|\n",
      "|[18.1226775380419...|    0|[-0.2431629365422...|[0.43950704258104...|       1.0|\n",
      "|[18.1294228190874...|    0|[-0.2398926355215...|[0.44031280919035...|       1.0|\n",
      "|[18.1307237257727...|    0|[-0.2392619195540...|[0.44046824706468...|       1.0|\n",
      "|[18.1940906350762...|    0|[-0.2085398685716...|[0.44805315570446...|       1.0|\n",
      "|[18.2010518091315...|    0|[-0.2051648965780...|[0.44888793698733...|       1.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n",
      "areaUnderROC:0.5164835164835165\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "model = lr.fit(train)\n",
    "\n",
    "validpredicts = model.transform(validation)\n",
    "print(validpredicts.show())\n",
    "reval = BinaryClassificationEvaluator()\n",
    "print (reval.getMetricName() +\":\" + str(reval.evaluate(validpredicts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "60c9388f-7b66-43dd-b018-950e538df2ba",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Outcomes\n",
    "- The model uses sentiment scores generated using FinBert transformer model as well as the log of volume traded.\n",
    "- As observed above, the Logistic Regression model predicts weather to buy or sell the stock using sentiment score with Area under ROC score of ~0.52\n",
    "- Evaluated on 2 models - random forest and logistic regression but since it gave better results on logistic regression, therefore only included logistic model here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fcd1f715-d063-470c-862f-5f201c2d1719",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Save processed vector assembler data to mongo db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6e8f5a5-4289-4b61-bdd5-12e5f83107fe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def sparseToDenseArray(sparse_array):\n",
    "    return sparse_array.toArray().tolist()\n",
    "\n",
    "udf_sparse_dense_array = udf(sparseToDenseArray, ArrayType(FloatType()))\n",
    "va_df_dense_v_to_array =  df_va.select(udf_sparse_dense_array(df_va[\"features\"]).alias(\"features\"), df_va[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8c17e99-fa6a-4064-871f-03523c115cf2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "collection = 'senti_processed_data'\n",
    "connection_string = f\"mongodb+srv://{mongo_username}:{mongo_password}@{mongo_ip_address}/{database_name}.{collection}\"\n",
    "va_df_dense_v_to_array.write.format(\"com.mongodb.spark.sql.DefaultSource\")\\\n",
    "                     .mode(\"overwrite\")\\\n",
    "                     .option(\"uri\", connection_string)\\\n",
    "                     .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "be14f88e-7e7a-425f-b07c-84080ed5f0bf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "g14_project_task3_ity",
   "notebookOrigID": 4339210645485415,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

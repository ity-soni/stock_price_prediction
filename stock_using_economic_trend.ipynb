{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b607686-743c-4b4a-a6c0-20ebaa8b0f43",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Predicting stock market sentiment using Economic Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b1739b2-d3e4-4599-a72e-96c1a0b21e3f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator, BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89dbea67-a07b-4309-b609-6d9cf54bb650",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "database = '####'\n",
    "collection = 'ts_da'\n",
    "user_name = '####'\n",
    "password = '####'\n",
    "address = 'g14cluster.tlbgg.mongodb.net'\n",
    "connection_string = f\"mongodb+srv://{user_name}:{password}@{address}/{database}.{collection}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26ccd66d-54dd-4bfe-9d90-6bb2fd6a8c8e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Functions\n",
    "- StringIndexer\n",
    "- OneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a855dd9-1d59-4161-9b97-00d39fc55573",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def indexStringColumns(df, cols):\n",
    "    # variable newdf will be updated several times\n",
    "    newdf = df\n",
    "    for c in cols:\n",
    "        # For each given colum, fits StringIndexerModel.\n",
    "        si = StringIndexer(inputCol=c, outputCol=c+\"-num\").setHandleInvalid(\"keep\")\n",
    "        sm = si.fit(newdf)\n",
    "        # Creates a DataFame by putting the transformed values in the new colum with suffix \"-num\" \n",
    "        # and then drops the original columns.\n",
    "        # and drop the \"-num\" suffix\n",
    "        newdf = sm.transform(newdf).drop(c)\n",
    "        newdf = newdf.withColumnRenamed(c+\"-num\", c)\n",
    "    return newdf\n",
    "\n",
    "def oneHotEncodeColumns(df, cols):\n",
    "    newdf = df\n",
    "    for c in cols:\n",
    "        # For each given colum, create OneHotEncoder. \n",
    "        # dropLast : Whether to drop the last category in the encoded vector (default: true)\n",
    "        ohe = OneHotEncoder(inputCol=c, outputCol=c+\"-onehot\", dropLast=False)\n",
    "        ohe_model = ohe.fit(newdf)\n",
    "        #Creates a DataFame by putting the transformed values in the new colum with suffix \"-onehot\" \n",
    "        #and then drops the original columns.\n",
    "        #and drop the \"-onehot\" suffix. \n",
    "        newdf = ohe_model.transform(newdf).drop(c)\n",
    "        newdf = newdf.withColumnRenamed(c+\"-onehot\", c)\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f93a7360-6058-41bc-8fcb-5d187c666bfb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Preprocessing pipeline\n",
    "- Fetch monthly Economic trends data\n",
    "- Fetch Stock Quote trends data\n",
    "- Preprocessing to obtain the percent change in stock price and other indicators from previous close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4391c9a-a78c-449a-baf4-25036fe6b529",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+-----+------+------------+-----------+--------+-------+--------+---------+---------------+-----------+---------------+---------------------+\n",
      "|      date|year|month|pc_cpi|pc_10year_ty|pc_2year_ty|pc_brent|pc_corn|pc_wheat|pc_copper|pc_unemployment|pc_durables|pc_retail_sales|pc_federal_funds_rate|\n",
      "+----------+----+-----+------+------------+-----------+--------+-------+--------+---------+---------------+-----------+---------------+---------------------+\n",
      "|2023-01-01|2022|   12|0.7995|     -2.4862|    -1.8648|  1.9525|    0.2| -1.0993|   7.6006|        -2.8571|   -15.7878|       -17.7817|               5.6098|\n",
      "|2022-12-01|2022|   11|-0.307|     -6.9409|    -4.6667|-11.4855| -5.825| -6.0044|   3.9905|        -2.7778|    14.2997|         7.8411|               8.4656|\n",
      "|2022-11-01|2022|   10|-0.101|     -2.2613|     2.7397| -2.0465|-6.5852| -2.6527|   5.2121|        -2.7027|     -4.948|         2.0948|              22.7273|\n",
      "|2022-10-01|2022|    9|0.4056|     13.0682|    13.4715|  3.9773| 9.9208|  2.1341|  -1.2255|         5.7143|    -5.7986|         3.4603|              20.3125|\n",
      "|2022-09-01|2022|    8|0.2151|     21.3793|    18.7692|-10.6421| 6.3332|  7.2149|  -3.0635|        -5.4054|     3.7981|        -5.8763|               9.8712|\n",
      "+----------+----+-----+------+------------+-----------+--------+-------+--------+---------+---------------+-----------+---------------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "count before dropna: 313\n",
      "count after dropna: 312\n",
      "Out[5]: 0"
     ]
    }
   ],
   "source": [
    "collection = 'econ_data'\n",
    "connection_string = f\"mongodb+srv://{user_name}:{password}@{address}/{database}.{collection}\"\n",
    "df_econ = spark.read.format(\"mongo\").option(\"uri\",connection_string).load()\n",
    "df_econ = df_econ.withColumn(\"date\",col(\"date\").cast(DateType())).withColumn('date_n',date_add(col('date'),-1).alias('date_n'))\n",
    "df_econ = df_econ.withColumn('month', date_format(col('date_n'),'M').cast(LongType())).withColumn('year', date_format(col('date_n'),'y').cast(LongType()))\n",
    "econ_cols = ['cpi', '10year_ty', '2year_ty', 'brent', 'corn', 'wheat', 'copper', 'unemployment', 'durables', 'retail_sales', 'federal_funds_rate']\n",
    "for i in econ_cols:\n",
    "    df_econ = df_econ.withColumn(i,col(i).cast(FloatType()))\n",
    "    windowSpec  = Window.partitionBy().orderBy('date')\n",
    "    df_econ = df_econ.withColumn('prev_'+str(i), lag(i, 1).over(windowSpec))\n",
    "    df_econ = df_econ.withColumn('pc_'+str(i), round(100*(col(i) - col('prev_'+str(i)))/col('prev_'+str(i)), 4).cast(FloatType()))\n",
    "    \n",
    "pc_econ_cols = ['pc_'+str(i) for i in econ_cols]\n",
    "pc_econ_cols.insert(0, 'date')\n",
    "pc_econ_cols.insert(1, 'month')\n",
    "pc_econ_cols.insert(1, 'year')\n",
    "\n",
    "dff_econ = df_econ.select(pc_econ_cols).orderBy(['year', 'month'], ascending = [False, False])\n",
    "dff_econ.show(5)\n",
    "\n",
    "print(f'count before dropna: {dff_econ.count()}')\n",
    "dff_econ = dff_econ.na.drop()\n",
    "print(f'count after dropna: {dff_econ.count()}')\n",
    "\n",
    "# ts_ma\n",
    "collection = 'ts_ma'\n",
    "connection_string = f\"mongodb+srv://{user_name}:{password}@{address}/{database}.{collection}\"\n",
    "df_tsma = spark.read.format(\"mongo\").option(\"uri\",connection_string).load()\n",
    "df_tsma = df_tsma.withColumn(\"close\",col(\"close\").cast(\"float\"))\n",
    "df_tsma = df_tsma.withColumn(\"date\", df_tsma[\"date\"].cast(DateType())).withColumn(\"volume\", df_tsma[\"volume\"].cast(LongType())).withColumn('month', date_format(col('date'), 'M').cast(LongType())).withColumn('year', date_format(col('date'),'y').cast(LongType())).withColumn('logvol', log(col('volume')))\n",
    "\n",
    "@udf('int')\n",
    "def buy_sell(x):\n",
    "    if (x>=0): return 1\n",
    "    else: return 0\n",
    "\n",
    "windowSpec  = Window.partitionBy('symbol').orderBy(\"date\")\n",
    "df_tsma = df_tsma.select('date', 'year', 'month', 'symbol', 'logvol', 'close', lag('close', 1).over(windowSpec).alias('close_prev'))\n",
    "df_tsma = df_tsma.withColumn('percent_change', round(100*(col('close') - col('close_prev'))/col('close_prev'), 4).cast(FloatType()))\n",
    "df_tsma = df_tsma.na.drop(subset=['percent_change'])\n",
    "df_tsma = df_tsma.withColumn('buysell', buy_sell(col('percent_change')))\n",
    "\n",
    "#checking null\n",
    "df_tsma.filter(df_tsma['percent_change'].isNull()).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c85cb603-415d-43f0-bcc1-db9c786309d3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Joining, Indexing, OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61c5735f-c8ed-4b4b-a801-68ae0c0247b5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+------+------------------+--------+----------+--------------+-------+----------+------+------------+-----------+--------+-------+--------+---------+---------------+-----------+---------------+---------------------+\n",
      "|year|month|      date|symbol|            logvol|   close|close_prev|percent_change|buysell|      date|pc_cpi|pc_10year_ty|pc_2year_ty|pc_brent|pc_corn|pc_wheat|pc_copper|pc_unemployment|pc_durables|pc_retail_sales|pc_federal_funds_rate|\n",
      "+----+-----+----------+------+------------------+--------+----------+--------------+-------+----------+------+------------+-----------+--------+-------+--------+---------+---------------+-----------+---------------+---------------------+\n",
      "|2022|   12|2022-12-30|  AAPL|21.239515506344638|129.7324|  147.6183|      -12.1163|      0|2023-01-01|0.7995|     -2.4862|    -1.8648|  1.9525|    0.2| -1.0993|   7.6006|        -2.8571|   -15.7878|       -17.7817|               5.6098|\n",
      "|2022|   11|2022-11-30|  AAPL| 21.26846286900817|147.6183|  152.6598|       -3.3024|      0|2022-12-01|-0.307|     -6.9409|    -4.6667|-11.4855| -5.825| -6.0044|   3.9905|        -2.7778|    14.2997|         7.8411|               8.4656|\n",
      "|2022|   10|2022-10-31|  AAPL| 21.34833830152846|152.6598|  137.5869|       10.9552|      1|2022-11-01|-0.101|     -2.2613|     2.7397| -2.0465|-6.5852| -2.6527|   5.2121|        -2.7027|     -4.948|         2.0948|              22.7273|\n",
      "+----+-----+----------+------+------------------+--------+----------+--------------+-------+----------+------+------------+-----------+--------+-------+--------+---------+---------------+-----------+---------------+---------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+----------+------------------+--------+----------+--------------+-------+----------+------+------------+-----------+--------+-------+--------+---------+---------------+-----------+---------------+---------------------+------+-------------------+---------------+\n",
      "|      date|            logvol|   close|close_prev|percent_change|buysell|      date|pc_cpi|pc_10year_ty|pc_2year_ty|pc_brent|pc_corn|pc_wheat|pc_copper|pc_unemployment|pc_durables|pc_retail_sales|pc_federal_funds_rate|symbol|               year|          month|\n",
      "+----------+------------------+--------+----------+--------------+-------+----------+------+------------+-----------+--------+-------+--------+---------+---------------+-----------+---------------+---------------------+------+-------------------+---------------+\n",
      "|2022-12-30|21.239515506344638|129.7324|  147.6183|      -12.1163|      0|2023-01-01|0.7995|     -2.4862|    -1.8648|  1.9525|    0.2| -1.0993|   7.6006|        -2.8571|   -15.7878|       -17.7817|               5.6098|   0.0|(2023,[2022],[1.0])|(13,[12],[1.0])|\n",
      "|2022-11-30| 21.26846286900817|147.6183|  152.6598|       -3.3024|      0|2022-12-01|-0.307|     -6.9409|    -4.6667|-11.4855| -5.825| -6.0044|   3.9905|        -2.7778|    14.2997|         7.8411|               8.4656|   0.0|(2023,[2022],[1.0])|(13,[11],[1.0])|\n",
      "|2022-10-31| 21.34833830152846|152.6598|  137.5869|       10.9552|      1|2022-11-01|-0.101|     -2.2613|     2.7397| -2.0465|-6.5852| -2.6527|   5.2121|        -2.7027|     -4.948|         2.0948|              22.7273|   0.0|(2023,[2022],[1.0])|(13,[10],[1.0])|\n",
      "|2022-09-30|21.457539676171777|137.5869|  156.5225|      -12.0977|      0|2022-10-01|0.4056|     13.0682|    13.4715|  3.9773| 9.9208|  2.1341|  -1.2255|         5.7143|    -5.7986|         3.4603|              20.3125|   0.0|(2023,[2022],[1.0])| (13,[9],[1.0])|\n",
      "|2022-08-31| 21.13520026381315|156.5225|  161.5643|       -3.1206|      0|2022-09-01|0.2151|     21.3793|    18.7692|-10.6421| 6.3332|  7.2149|  -3.0635|        -5.4054|     3.7981|        -5.8763|               9.8712|   0.0|(2023,[2022],[1.0])| (13,[8],[1.0])|\n",
      "+----------+------------------+--------+----------+--------------+-------+----------+------+------------+-----------+--------+-------+--------+---------+---------------+-----------+---------------+---------------------+------+-------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# joining the two dataframes\n",
    "df_j1 = df_tsma.join(dff_econ, ['year', 'month']).orderBy(['symbol','year', 'month'], ascending = [True, False, False])\n",
    "df_j1.show(3)\n",
    "\n",
    "# String Indexing\n",
    "str_cols = ['symbol']\n",
    "df_stri = indexStringColumns(df_j1, str_cols)\n",
    "\n",
    "# One Hot Encoding\n",
    "cat_cols = ['year', 'month']\n",
    "# new joined and transformed dataframe\n",
    "df_jt1 = oneHotEncodeColumns(df_stri, cat_cols)\n",
    "df_jt1.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "faaa41aa-b55b-4e84-953f-f8ab8fa393dd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Create a dataframe with Features and Labels\n",
    "- Using VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80acf3e6-fe42-4d0a-aa09-708c04f502de",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class_incols = ['year', 'month', 'logvol', 'pc_cpi', 'pc_10year_ty', 'pc_2year_ty', 'pc_brent', 'pc_corn', 'pc_wheat', \n",
    "              'pc_copper', 'pc_unemployment', 'pc_durables', 'pc_retail_sales', 'pc_federal_funds_rate', 'symbol']\n",
    "class_incols_num = ['logvol', 'pc_cpi', 'pc_10year_ty', 'pc_2year_ty', 'pc_brent', 'pc_corn', 'pc_wheat', \n",
    "              'pc_copper', 'pc_unemployment', 'pc_durables', 'pc_retail_sales', 'pc_federal_funds_rate']\n",
    "va = VectorAssembler(outputCol=\"features\",\n",
    "                     inputCols=class_incols_num)\n",
    "df_va = va.transform(df_jt1).select('features', 'buysell').withColumnRenamed('buysell', 'label')\n",
    "\n",
    "#splitting the data\n",
    "splits = df_va.randomSplit([0.8, 0.2], seed = 1)\n",
    "train = splits[0].cache()\n",
    "validation = splits[1].cache()\n",
    "#setting evaluator\n",
    "reval = BinaryClassificationEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "187beaf5-d60d-44c6-92a4-7e4c9af656a9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class_incols = ['year', 'month', 'logvol', 'pc_cpi', 'pc_10year_ty', 'pc_2year_ty', 'pc_brent', 'pc_corn', 'pc_wheat', \n",
    "              'pc_copper', 'pc_unemployment', 'pc_durables', 'pc_retail_sales', 'pc_federal_funds_rate', 'symbol']\n",
    "class_incols_num = ['logvol', 'pc_cpi', 'pc_10year_ty', 'pc_2year_ty', 'pc_brent', 'pc_corn', 'pc_wheat', \n",
    "              'pc_copper', 'pc_unemployment', 'pc_durables', 'pc_retail_sales', 'pc_federal_funds_rate']\n",
    "# considering only numeric columns\n",
    "va = VectorAssembler(outputCol=\"features\",\n",
    "                     inputCols=class_incols_num + ['symbol'])\n",
    "df_va = va.transform(df_jt1).select('features', 'buysell').withColumnRenamed('buysell', 'label')\n",
    "\n",
    "#splitting the data\n",
    "splits = df_va.randomSplit([0.8, 0.2], seed = 1)\n",
    "train = splits[0].cache()\n",
    "validation = splits[1].cache()\n",
    "#setting evaluator\n",
    "reval = BinaryClassificationEvaluator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8c108d7-9ae3-4ed9-b31d-17b589b5a860",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Random Forest Classifier with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41673999-238b-49a2-8985-ffefea92a5d2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "areaUnderROC:0.6564704635601175\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|[21.2441692119621...|    0|[5.43452380952380...|[0.77636054421768...|       0.0|\n",
      "|[21.2608902109102...|    0|[1.16666666666666...|[0.16666666666666...|       1.0|\n",
      "|[20.2476123058214...|    1|[1.92692307692307...|[0.27527472527472...|       1.0|\n",
      "|[20.4425239337101...|    0|[6.89858793324775...|[0.98551256189253...|       0.0|\n",
      "|[21.7863606414366...|    0|[5.71428571428571...|[0.81632653061224...|       0.0|\n",
      "|[22.0808502543149...|    0|[3.28518518518518...|[0.46931216931216...|       1.0|\n",
      "|[19.9736344874276...|    1|[1.44514767932489...|[0.20644966847498...|       1.0|\n",
      "|[20.3427602511708...|    0|[1.23269454123112...|[0.17609922017587...|       1.0|\n",
      "|[20.2757991857990...|    0|[0.36616161616161...|[0.05230880230880...|       1.0|\n",
      "|[20.1493782192176...|    1|[3.50384615384615...|[0.50054945054945...|       0.0|\n",
      "|[20.1698258963959...|    1|[1.15897435897435...|[0.16556776556776...|       1.0|\n",
      "|[20.3460668702254...|    1|[0.50322848740570...|[0.07188978391510...|       1.0|\n",
      "|[20.5938480757264...|    0|[3.81816436251920...|[0.54545205178845...|       0.0|\n",
      "|[20.6427347906383...|    0|       [3.125,3.875]|[0.44642857142857...|       1.0|\n",
      "|[20.8309570804466...|    1|[1.22474747474747...|[0.17496392496392...|       1.0|\n",
      "|[20.9087399807782...|    0|[3.56666666666666...|[0.50952380952380...|       0.0|\n",
      "|[21.0309564875438...|    1|       [0.975,6.025]|[0.13928571428571...|       1.0|\n",
      "|[19.2687101938055...|    1|[0.78812973178692...|[0.11258996168384...|       1.0|\n",
      "|[19.5619367268378...|    0|[2.96300482218203...|[0.42328640316886...|       1.0|\n",
      "|[19.6368147007900...|    1|[1.54633815551537...|[0.22090545078791...|       1.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# with CV\n",
    "# this takes a long time to run\n",
    "rf = RandomForestClassifier()\n",
    "cv = CrossValidator().setEstimator(rf).setEvaluator(reval).setNumFolds(5)\n",
    "\n",
    "#ParamGridBuilder() – combinations of parameters and their values.\n",
    "paramGrid = ParamGridBuilder().addGrid(rf.maxDepth, [5, 10, 15])\\\n",
    "                              .addGrid(rf.numTrees, [3, 7, 10]).build()\n",
    "\n",
    "cv.setEstimatorParamMaps(paramGrid)\n",
    "cvmodel = cv.fit(train)\n",
    "cvrf_pred = cvmodel.transform(validation)\n",
    "print (reval.getMetricName() +\":\" + str(reval.evaluate(cvrf_pred)))\n",
    "cvrf_pred.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1673e7a-d69e-4e38-8753-48907ba243e9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d4ff56b-ff75-4286-b1da-36a781e200fb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "areaUnderROC:0.6460774517818755\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|[21.2441692119621...|    0|           [1.0,4.0]|           [0.2,0.8]|       1.0|\n",
      "|[21.2608902109102...|    0|           [4.0,1.0]|           [0.8,0.2]|       0.0|\n",
      "|[20.2476123058214...|    1|[0.97656691134952...|[0.19531338226990...|       1.0|\n",
      "|[20.4425239337101...|    0|           [4.2,0.8]|[0.84000000000000...|       0.0|\n",
      "|[21.7863606414366...|    0|[4.05555555555555...|[0.81111111111111...|       0.0|\n",
      "|[22.0808502543149...|    0|           [2.0,3.0]|           [0.4,0.6]|       1.0|\n",
      "|[19.9736344874276...|    1|[1.30817610062893...|[0.26163522012578...|       1.0|\n",
      "|[20.3427602511708...|    0|[0.16278166278166...|[0.03255633255633...|       1.0|\n",
      "|[20.2757991857990...|    0|[0.54073171314550...|[0.10814634262910...|       1.0|\n",
      "|[20.1493782192176...|    1|[0.33847913093196...|[0.06769582618639...|       1.0|\n",
      "|[20.1698258963959...|    1|[1.66666666666666...|[0.33333333333333...|       1.0|\n",
      "|[20.3460668702254...|    1|           [2.0,3.0]|           [0.4,0.6]|       1.0|\n",
      "|[20.5938480757264...|    0|         [3.88,1.12]|[0.776,0.22400000...|       0.0|\n",
      "|[20.6427347906383...|    0|[0.89256410256410...|[0.17851282051282...|       1.0|\n",
      "|[20.8309570804466...|    1|           [1.0,4.0]|           [0.2,0.8]|       1.0|\n",
      "|[20.9087399807782...|    0|[3.06976702217891...|[0.61395340443578...|       0.0|\n",
      "|[21.0309564875438...|    1|[0.02702702702702...|[0.00540540540540...|       1.0|\n",
      "|[19.2687101938055...|    1|[0.55499325236167...|[0.11099865047233...|       1.0|\n",
      "|[19.5619367268378...|    0|[3.74952697853461...|[0.74990539570692...|       0.0|\n",
      "|[19.6368147007900...|    1|[0.47275641025641...|[0.09455128205128...|       1.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# without CV\n",
    "rf = RandomForestClassifier(maxDepth=14, numTrees = 5)\n",
    "rfmodel = rf.fit(train)\n",
    "\n",
    "rf_pred = rfmodel.transform(validation)\n",
    "print (reval.getMetricName() +\":\" + str(reval.evaluate(rf_pred)))\n",
    "rf_pred.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "893c253a-4df5-4ac0-b5fa-879ae1b04f75",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Observations\n",
    "- Raw data fetched from MongoDB was pre-processed using StringIndexer and OneHotEncoding and a UDF to generate percent change in various economic indicators across time.\n",
    "- This was then compared to stock price percentage change for the same time period\n",
    "- Following features were taken into consideration in the final model\n",
    "  - 'logvol': log value of the $ amount of traded value\n",
    "  - 'pc_cpi': percent change in Consumer Price index\n",
    "  - 'pc_10year_ty': percent change in 10 year Treasury Yield\n",
    "  - 'pc_2year_ty': percent change in 2 year treasury yield\n",
    "  - 'pc_brent': percent change in brent (crude) price\n",
    "  - 'pc_corn': percent change in corn price\n",
    "  - 'pc_wheat': percent change in wheat price\n",
    "  - 'pc_copper': percent change in copper price\n",
    "  - 'pc_unemployment': percent change in unemployment\n",
    "  - 'pc_durables': percent change in durables purchase by consumers\n",
    "  - 'pc_retail_sales': percent change in retail sales\n",
    "  - 'pc_federal_funds_rate': percent change federal funds rate\n",
    "- It can be seen that the above Model's Area under the ROC curve is ~0.65, which indicates that the model performs better than a random model which would have Area under ROC to be 0.50\n",
    "- Several other models were given a try (Random Forest CV) out of which random forest with maxDepth = 14 and numTrees = 5 works the best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c469fbc8-8982-4b5a-a393-086893d19d60",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### VectorAssembler feature and label data - Saved to Mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2888a049-ee81-4776-9c33-018748282873",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def sparseToDenseArray(sparse_array):\n",
    "    return sparse_array.toArray().tolist()\n",
    "\n",
    "udf_sparse_dense_array = udf(sparseToDenseArray, ArrayType(FloatType()))\n",
    "df_va_dense_v_to_array =  df_va.select(udf_sparse_dense_array(df_va[\"features\"]).alias(\"features\"), df_va[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "314afaef-26e2-4355-ac4f-ab8d596b6353",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "collection = 'ts_ma_econ_data_va'\n",
    "connection_string = f\"mongodb+srv://{user_name}:{password}@{address}/{database}.{collection}\"\n",
    "df_va_dense_v_to_array.write.format(\"com.mongodb.spark.sql.DefaultSource\")\\\n",
    "                     .mode(\"overwrite\")\\\n",
    "                     .option(\"uri\", connection_string)\\\n",
    "                     .save()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "g14_project_task3_deepak",
   "notebookOrigID": 2544359969782500,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
